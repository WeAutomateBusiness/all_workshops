{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta primeira c√©lula, estamos reunindo as ‚Äúpe√ßas‚Äù essenciais que ser√£o os alicerces do nosso notebook de padroniza√ß√£o de dados de produtos. Pense nela como a bancada de laborat√≥rio onde voc√™ prepara todos os reagentes antes de come√ßar o experimento:\n",
    "\n",
    "import json\n",
    "\n",
    "Carrega e salva configura√ß√µes e resultados em formato JSON, nossa linguagem universal para trocar informa√ß√µes entre sistemas.\n",
    "\n",
    "LangChain & Chroma (Vector Store)\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "Aqui trazemos o Chroma, que vai armazenar vetores de embedding dos textos dos produtos, e o SemanticSimilarityExampleSelector, nosso ‚Äúcurador‚Äù que escolhe exemplos mais relevantes com base em similaridade sem√¢ntica.\n",
    "\n",
    "Templates de Prompt\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "Essas classes permitem montar conversas estruturadas (prompts) com o modelo de IA. √â nelas que definiremos o ‚Äúroteiro‚Äù criativo para o ChatGPT transformar descri√ß√µes livres em campos padronizados.\n",
    "\n",
    "OpenAI & Embeddings\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "Aqui √© onde chamamos a m√°gica do ChatOpenAI para gerar texto e do OpenAIEmbeddings para converter frases dos produtos em vetores num√©ricos que o Chroma entende.\n",
    "\n",
    "Dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "Garante que suas chaves de API e outras vari√°veis sens√≠veis fiquem guardadas num arquivo .env, sem vazar no c√≥digo.\n",
    "\n",
    "Modelo de Dom√≠nio\n",
    "\n",
    "from product_model import Product\n",
    "\n",
    "Importa a classe Product, que define como queremos que nossos dados padronizados de produto sejam estruturados: nome, categoria, atributos, etc.\n",
    "\n",
    "Pandas & NumPy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "S√£o nossas lentes e escalpelo para ler, fatiar, transformar e manipular tabelas e matrizes de dados com agilidade.\n",
    "\n",
    "üåü Por que isso importa?\n",
    "Ao juntar essas bibliotecas, temos:\n",
    "\n",
    "Leitura/Grava√ß√£o de configura√ß√µes (JSON).\n",
    "\n",
    "Armazenamento de vetores sem√¢nticos (Chroma).\n",
    "\n",
    "Sele√ß√£o Inteligente de exemplos (SemanticSimilarity).\n",
    "\n",
    "Montagem de prompts din√¢micos (ChatPromptTemplate).\n",
    "\n",
    "Chamada ao ponto de entrada da IA (ChatOpenAI).\n",
    "\n",
    "Prote√ß√£o das credenciais (dotenv).\n",
    "\n",
    "Estrutura√ß√£o do resultado (Product).\n",
    "\n",
    "Manipula√ß√£o de dados em massa (pandas & numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from product_model import Product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_dotenv(): carrega vari√°veis de ambiente a partir do arquivo .env.\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\"): inicializa o GPT-4o-mini com temperatura zero, garantindo sa√≠das consistentes e reproduz√≠veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prop√≥sito: transforma cada linha do DataFrame num par input/output pronto para alimentar o pipeline de IA.\n",
    "\n",
    "‚Äúinput‚Äù: pega o texto livre em row[\"description\"].\n",
    "\n",
    "‚Äúoutput‚Äù: gera uma string JSON (com acentua√ß√£o preservada) contendo os campos padronizados do Product ‚Äî tipo, marcas, varia√ß√£o, embalagem, unidade e quantidade.\n",
    "\n",
    "Em resumo, esta fun√ß√£o empacota seu dado bruto e a estrutura esperada num exemplo √∫nico, ideal para treinar ou chamar o modelo de forma consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_json(row):\n",
    "    return {\n",
    "        \"input\": row[\"description\"],\n",
    "        \"output\": json.dumps(\n",
    "            {\n",
    "                \"type\": row.get(\"type\"),\n",
    "                \"primary_brand\": row.get(\"primary_brand\"),\n",
    "                \"secondary_brand\": row.get(\"secondary_brand\"),\n",
    "                \"variation\": row.get(\"variation\"),\n",
    "                \"container\": row.get(\"container\"),\n",
    "                \"container_type\": row.get(\"container_type\"),\n",
    "                \"measure\": row.get(\"measure\"),\n",
    "                \"unity\": row.get(\"unity\"),\n",
    "                \"amount\": row.get(\"amount\"),\n",
    "            },\n",
    "            ensure_ascii=False,\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L√™ o arquivo examples.csv em um DataFrame.\n",
    "\n",
    "Converte valores NaN em None para compatibilidade com JSON e IA.\n",
    "\n",
    "Exibe as primeiras linhas (head) para verifica√ß√£o r√°pida dos exemplos dispon√≠veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>primary_brand</th>\n",
       "      <th>secondary_brand</th>\n",
       "      <th>variation</th>\n",
       "      <th>container</th>\n",
       "      <th>container_type</th>\n",
       "      <th>amount</th>\n",
       "      <th>measure</th>\n",
       "      <th>unity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CERVEJA ANTARCTICA PILSEN GARRAFA VIDRO 600ML</td>\n",
       "      <td>cerveja</td>\n",
       "      <td>antarctica</td>\n",
       "      <td>None</td>\n",
       "      <td>pilsen</td>\n",
       "      <td>garrafa</td>\n",
       "      <td>vidro</td>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CERVEJA PATAGONIA BOHEMIAN PILSENER GARRAFA ON...</td>\n",
       "      <td>cerveja</td>\n",
       "      <td>patagonia</td>\n",
       "      <td>None</td>\n",
       "      <td>bohemian pilsener</td>\n",
       "      <td>garrafa</td>\n",
       "      <td>one way</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CERVEJA SKOL BEATS SECRET LT 269ML</td>\n",
       "      <td>cerveja</td>\n",
       "      <td>skol</td>\n",
       "      <td>beats</td>\n",
       "      <td>secret</td>\n",
       "      <td>lata</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>269.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CERV. CARACU LN 355ML C/6</td>\n",
       "      <td>cerveja</td>\n",
       "      <td>caracu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>long neck</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>355.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUCO DE UVA ALIAN√áA TINTO INTEGRAL 1.5L</td>\n",
       "      <td>suco</td>\n",
       "      <td>alian√ßa</td>\n",
       "      <td>None</td>\n",
       "      <td>uva tinto integral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description     type primary_brand  \\\n",
       "0      CERVEJA ANTARCTICA PILSEN GARRAFA VIDRO 600ML  cerveja    antarctica   \n",
       "1  CERVEJA PATAGONIA BOHEMIAN PILSENER GARRAFA ON...  cerveja     patagonia   \n",
       "2                 CERVEJA SKOL BEATS SECRET LT 269ML  cerveja          skol   \n",
       "3                          CERV. CARACU LN 355ML C/6  cerveja        caracu   \n",
       "4            SUCO DE UVA ALIAN√áA TINTO INTEGRAL 1.5L     suco       alian√ßa   \n",
       "\n",
       "  secondary_brand           variation  container container_type  amount  \\\n",
       "0            None              pilsen    garrafa          vidro       1   \n",
       "1            None   bohemian pilsener    garrafa        one way       1   \n",
       "2           beats              secret       lata           None       1   \n",
       "3            None                None  long neck           None       6   \n",
       "4            None  uva tinto integral       None           None       1   \n",
       "\n",
       "   measure unity  \n",
       "0    600.0    ml  \n",
       "1    740.0    ml  \n",
       "2    269.0    ml  \n",
       "3    355.0    ml  \n",
       "4      1.5     L  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_df = pd.read_csv(\"examples.csv\").replace({np.nan: None})\n",
    "examples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa row_to_json para mapear cada linha de examples_df a um dicion√°rio {input, output}.\n",
    "\n",
    "Converte a s√©rie resultante em uma lista Python (examples_json), pronta para alimentar prompts Few-Shot ou seletores sem√¢nticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_json = examples_df.apply(row_to_json, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um seletor que armazena os exemplos como vetores no Chroma, usando embeddings do modelo text-embedding-3-small.\n",
    "\n",
    "k=2 garante que, a cada chamada, voc√™ receba os 2 exemplos mais semanticamente relevantes para enriquecer seu prompt ou few-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples_json,\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    vectorstore_cls=Chroma,\n",
    "    k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um ChatPromptTemplate com duas mensagens encadeadas:\n",
    "\n",
    "Humano recebe {input} (descri√ß√£o bruta).\n",
    "\n",
    "IA responde com {output} (JSON padronizado).\n",
    "\n",
    "Esses placeholders ser√£o substitu√≠dos dinamicamente pelos exemplos ou inputs reais no momento da chamada ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instancia um FewShotChatMessagePromptTemplate que combina:\n",
    "\n",
    "example_selector: busca os 2 exemplos mais relevantes via similaridade sem√¢ntica.\n",
    "\n",
    "example_prompt: formata cada exemplo como pares ‚Äúhumano ‚Üí IA‚Äù (descri√ß√£o bruta e JSON padronizado).\n",
    "\n",
    "Por que isso importa?\n",
    "Ao chamar esse prompt, o sistema:\n",
    "\n",
    "Seleciona automaticamente os exemplos mais pr√≥ximos do seu item atual.\n",
    "\n",
    "Insere esses pares formatados no in√≠cio da conversa.\n",
    "\n",
    "Garante que o modelo receba contexto personalizado, melhorando a precis√£o da padroniza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema: define o papel do modelo (‚Äúexpert extraction algorithm‚Äù) e for√ßa respostas em portugu√™s.\n",
    "\n",
    "Few-Shot: injeta automaticamente os 2 exemplos sem√¢nticos mais relevantes para guiar a extra√ß√£o.\n",
    "\n",
    "Humano: insere a descri√ß√£o real do produto ({input}) para que o modelo extraia e retorne o JSON padronizado.\n",
    "\n",
    "Esse prompt une contexto, exemplos e entrada din√¢mica, garantindo que o LLM entenda exatamente o papel e o formato de sa√≠da desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Your job is to retrieve information from the product description. \"\n",
    "            \"Answer in portuguese and in portuguese only. \"\n",
    "            \"Here are some examples on how to do this job:\\n\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que faz: envia ao llm o prompt completo (contexto de sistema, exemplos few-shot e o nosso novo input) usando prompt.invoke, e captura o fluxo de mensagens que o modelo gera.\n",
    "\n",
    "Input de exemplo: \"DESODORANTE REXONA MAN 120ml\" um descritivo t√≠pico de produto.\n",
    "\n",
    "Output: uma lista de objetos messages contendo:\n",
    "\n",
    "A mensagem de sistema com instru√ß√µes.\n",
    "\n",
    "Os exemplos selecionados e formatados.\n",
    "\n",
    "A mensagem do usu√°rio com o input real.\n",
    "\n",
    "A resposta da IA, que vir√° como JSON padronizado com campos como type, primary_brand, measure, etc.\n",
    "\n",
    "Esse passo valida toda a configura√ß√£o: garante que, a partir de uma descri√ß√£o livre, o modelo retorne exatamente o JSON estruturado que voc√™ precisa para sua base de dados de produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an expert extraction algorithm. Your job is to retrieve information from the product description. Answer in portuguese and in portuguese only. Here are some examples on how to do this job:\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='DESODORANTE REXONA V8 150ML', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='{\"type\": \"desodorante\", \"primary_brand\": \"rexona\", \"secondary_brand\": null, \"variation\": \"v8\", \"container\": null, \"container_type\": null, \"measure\": 150.0, \"unity\": \"ml\", \"amount\": 1}', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='DESODORANTE REXONA V8 150ML', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='{\"type\": \"desodorante\", \"primary_brand\": \"rexona\", \"secondary_brand\": null, \"variation\": \"v8\", \"container\": null, \"container_type\": null, \"measure\": 150.0, \"unity\": \"ml\", \"amount\": 1}', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='DESODORANTE REXONA MAN 120ml', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"input\": \"DESODORANTE REXONA MAN 120ml\"}).messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que faz: usa o operador | para encadear o prompt e o LLM configurado para sa√≠da estruturada.\n",
    "\n",
    "llm.with_structured_output(schema=Product): instrui o modelo a devolver diretamente um objeto do tipo Product, respeitando o schema (campos e tipos) definidos na classe.\n",
    "\n",
    "Vantagem: elimina parsing manual‚Äîvoc√™ recebe inst√¢ncias de Product validadas e prontas para uso no seu fluxo de padroniza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response = chain.invoke({\"input\": \"DESODORANTE REXONA MAN 120ml\"}): executa todo o fluxo (prompt + LLM com sa√≠da estruturada) e retorna um objeto Product preenchido com os campos extra√≠dos.\n",
    "\n",
    "O response j√° √© uma inst√¢ncia v√°lida de Product, pronta para uso imediato em an√°lises, grava√ß√£o em banco ou exporta√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\": \"DESODORANTE REXONA MAN 120ml\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response.__dict__: acessa o dicion√°rio interno do objeto Product, exibindo todos os atributos (tipo, marca, varia√ß√£o, medida, etc.) e seus valores extra√≠dos.\n",
    "\n",
    "Objetivo: validar de forma r√°pida e leg√≠vel o conte√∫do da inst√¢ncia retornada pela pipeline, conferindo que cada campo foi preenchido conforme esperado.\n",
    "\n",
    "Uso pr√°tico: ideal para debugging ou antes de persistir os dados em um banco ou exportar para outro formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'desodorante',\n",
       " 'primary_brand': 'rexona',\n",
       " 'secondary_brand': None,\n",
       " 'variation': 'man',\n",
       " 'container': None,\n",
       " 'container_type': None,\n",
       " 'amount': 1,\n",
       " 'measure': 120.0,\n",
       " 'unity': 'ml'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
